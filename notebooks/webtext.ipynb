{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import dask\n",
    "from joblib import Memory, Parallel, delayed, dump\n",
    "from lsh import cache, minhash\n",
    "import numpy as np\n",
    "from itertools import chain, islice\n",
    "\n",
    "from utils.constants import DATA_DIR, OUTPUT_DIR\n",
    "from utils.webtext import load_meta, delayed_corpus, split_docs\n",
    "\n",
    "# Create joblib memory\n",
    "mem = Memory(OUTPUT_DIR / 'cache' / 'webtext_overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cached_meta = mem.cache(load_meta)\n",
    "\n",
    "wt_meta = cached_meta(DATA_DIR / 'webtext')\n",
    "wt_files = wt_meta[0]\n",
    "owtc_meta = cached_meta(DATA_DIR / 'openwebtext_bpe')\n",
    "owtc_files = owtc_meta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find duplicates with LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(document_feed, char_ngram=3, seeds=100, bands=5, hashbytes=4, n_jobs=1):\n",
    "    hasher = minhash.MinHasher(seeds=seeds, char_ngram=char_ngram, hashbytes=hashbytes)\n",
    "    if seeds % bands != 0:\n",
    "        raise ValueError('Seeds has to be a multiple of bands. {} % {} != 0'.format(seeds, bands))\n",
    "    \n",
    "    out = Parallel(n_jobs=n_jobs, verbose=1, backend='threading')(\n",
    "        delayed(lambda doc_id, doc: (doc_id, hasher.fingerprint(doc)))(doc_id, doc) \n",
    "        for doc_id, doc in document_feed\n",
    "    )\n",
    "\n",
    "    lshcache = cache.Cache(num_bands=bands, hasher=hasher)\n",
    "    for doc_id, fingerprint in out:\n",
    "        lshcache.add_fingerprint(fingerprint, doc_id=doc_id)\n",
    "    \n",
    "    return hasher, lshcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_iter(files: List[Path], name: str):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        print(\"Loading file:\", file)\n",
    "        shard = np.load(file)\n",
    "        docs = split_docs(shard)\n",
    "        for doc in docs:\n",
    "            # Yield name and doc as 4-byte\n",
    "            yield (i, name), doc.astype(np.int32).tobytes()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = chain(\n",
    "    corpus_iter(wt_files, name='wt'),\n",
    "    corpus_iter(owtc_files, name='owtc')\n",
    ")\n",
    "hasher, cache = train(corpus, n_jobs=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_duplicates = cache.get_all_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(all_duplicates, 'webtext_dups.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(cache, 'webtext_cache.joblib', compress='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates found from the same corpus and ensure all have webtext first to eliminate symmetric duplicates\n",
    "candidate_duplicates = set((x, y) if x[1] == 'wt' else (y, x) \n",
    "                           for x, y in all_duplicates if x[1] != y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidate_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_duplicates = cache.filter_candidates(candidate_duplicates, min_jaccard=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_duplicates)  # May want to change parameters to increase recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look up documents in corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = {'wt': delayed_corpus(wt_meta), 'owtc': delayed_corpus(owtc_meta)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_docs = []\n",
    "for i, (x, y) in enumerate(candidate_duplicates):\n",
    "    docs = tuple(corpora[corpus][idx] for idx, corpus in (x, y))\n",
    "    matching_docs.append(docs)\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_docs = dask.compute(*matching_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_docs[0][0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
