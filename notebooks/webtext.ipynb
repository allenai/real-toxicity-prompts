{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/gws/sgehman/language-model-toxicity\n"
     ]
    }
   ],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "\n",
    "from joblib import Memory, Parallel, delayed, dump\n",
    "from lsh import cache, minhash\n",
    "import numpy as np\n",
    "from itertools import chain, islice\n",
    "\n",
    "from utils.constants import DATA_DIR, OUTPUT_DIR\n",
    "from utils.webtext import load_meta, delayed_corpus, split_docs\n",
    "\n",
    "# Create joblib memory\n",
    "mem = Memory(OUTPUT_DIR / 'cache' / 'webtext_overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cached_meta = mem.cache(load_meta)\n",
    "\n",
    "wt_meta = cached_meta(DATA_DIR / 'webtext')\n",
    "wt_files = wt_meta[0]\n",
    "owtc_meta = cached_meta(DATA_DIR / 'openwebtext_bpe')\n",
    "owtc_files = owtc_meta[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find duplicates with LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(document_feed, char_ngram=3, seeds=100, bands=5, hashbytes=4, n_jobs=1):\n",
    "    hasher = minhash.MinHasher(seeds=seeds, char_ngram=char_ngram, hashbytes=hashbytes)\n",
    "    if seeds % bands != 0:\n",
    "        raise ValueError('Seeds has to be a multiple of bands. {} % {} != 0'.format(seeds, bands))\n",
    "    \n",
    "    out = Parallel(n_jobs=n_jobs, verbose=1, backend='threading')(\n",
    "        delayed(lambda doc_id, doc: (doc_id, hasher.fingerprint(doc)))(doc_id, doc) \n",
    "        for doc_id, doc in document_feed\n",
    "    )\n",
    "\n",
    "    lshcache = cache.Cache(num_bands=bands, hasher=hasher)\n",
    "    for doc_id, fingerprint in out:\n",
    "        lshcache.add_fingerprint(fingerprint, doc_id=doc_id)\n",
    "    \n",
    "    return hasher, lshcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_iter(files: List[Path], name: str):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        print(\"Loading file:\", file)\n",
    "        shard = np.load(file)\n",
    "        docs = split_docs(shard)\n",
    "        for doc in docs:\n",
    "            # Yield name and doc as 4-byte\n",
    "            yield (i, name), doc.astype(np.int32).tobytes()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Using backend ThreadingBackend with 96 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: /homes/gws/sgehman/data/language-model-toxicity/data/webtext/x00_tokens.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=96)]: Done  11 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=96)]: Done 261 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=96)]: Done 611 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=96)]: Done 1061 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=96)]: Done 1611 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=96)]: Done 2261 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=96)]: Done 3011 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=96)]: Done 3861 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=96)]: Done 4811 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=96)]: Done 5861 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=96)]: Done 7011 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=96)]: Done 8261 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=96)]: Done 9611 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=96)]: Done 11061 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=96)]: Done 12611 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=96)]: Done 14261 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=96)]: Done 16011 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=96)]: Done 17861 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=96)]: Done 19811 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=96)]: Done 21861 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=96)]: Done 24011 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=96)]: Done 26261 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=96)]: Done 28611 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=96)]: Done 31061 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=96)]: Done 33611 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=96)]: Done 36261 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=96)]: Done 39011 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=96)]: Done 41861 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=96)]: Done 44811 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=96)]: Done 47861 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=96)]: Done 51011 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=96)]: Done 54261 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=96)]: Done 57611 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=96)]: Done 61061 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=96)]: Done 64611 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=96)]: Done 68261 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=96)]: Done 72011 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=96)]: Done 75861 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=96)]: Done 79811 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=96)]: Done 83861 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=96)]: Done 88011 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=96)]: Done 92261 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=96)]: Done 96611 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=96)]: Done 101061 tasks      | elapsed:   42.6s\n"
     ]
    }
   ],
   "source": [
    "corpus = chain(\n",
    "    corpus_iter(wt_files, name='wt'),\n",
    "    corpus_iter(owtc_files, name='owtc')\n",
    ")\n",
    "hasher, cache = train(corpus, n_jobs=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_duplicates = cache.get_all_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(all_duplicates, 'webtext_dups.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_duplicates = [(x, y) for x, y in duplicates if x[1] != y[1]]\n",
    "filtered_duplicates = cache.filter_candidates(not_same_corpus, min_jaccard=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_corpus = delayed_corpus(wt_meta)\n",
    "owtc_corpus = delayed_corpus(owtc_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67320, 'owtc') (94085, 'wt')\n",
      "[  464 16009   286  2947  6736   874    11   543  5839   262  8919    12\n",
      "  3106 16009   286 23729    12    46    12    44] \n",
      " [  464 16009   286  2947  6736   874    11   543  5839   262  8919    12\n",
      "  3106 16009   286 23729    12    46    12    44]\n"
     ]
    }
   ],
   "source": [
    "def load_example(x):\n",
    "    idx = x[0]\n",
    "    if x[1] == 'wt':\n",
    "        return wt_corpus[idx].compute()\n",
    "    elif x[1] == 'owtc':\n",
    "        return owtc_corpus[idx].compute()\n",
    "    else:\n",
    "        raise RuntimeError\n",
    "\n",
    "for x, y in filtered_duplicates:\n",
    "    print(x, y)\n",
    "    x = load_example(x)\n",
    "    y = load_example(y)\n",
    "    print(x[:20], '\\n', y[:20])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
