{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.constants import DATA_DIR\n",
    "\n",
    "logging.disable(logging.CRITICAL)  # Disable logging from transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS = 50256\n",
    "\n",
    "def split_docs(tokens: np.array) -> np.array:\n",
    "    idx = np.nonzero(tokens == EOS)[0]\n",
    "    docs = np.split(tokens, idx)\n",
    "    docs = [doc[1:] for doc in docs if len(doc) > 1]\n",
    "    \n",
    "    # Pad all arrays\n",
    "    max_len = max(map(len, docs))\n",
    "    \n",
    "    for i in range(len(docs)):\n",
    "        doc = docs[i]\n",
    "        padded_doc = np.pad(doc, (0, max_len - len(doc)))\n",
    "        docs[i] = padded_doc\n",
    "\n",
    "    return np.stack(padded_docs)\n",
    "\n",
    "def load_meta(bpe_dir: Path, files_only=False):\n",
    "    files = [file for file in bpe_dir.iterdir() if file.suffix == '.npy']\n",
    "    if files_only:\n",
    "        return files\n",
    "    meta = [(np.count_nonzero(array == EOS) - 1, array.dtype)\n",
    "            for array \n",
    "            in tqdm(map(np.load, files), total=len(files), desc='Loading meta')]\n",
    "    shapes, dtypes = zip(*meta)\n",
    "    return files, shapes, dtypes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_dir = DATA_DIR / 'webtext'\n",
    "# wt_meta = load_meta(wt_dir)\n",
    "wt_files = load_meta(wt_dir, files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "owtc_dir = DATA_DIR / 'openwebtext_bpe'\n",
    "owtc_files = load_meta(owtc_dir, files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owtc_corpus = []\n",
    "# for shard in tqdm(map(np.load, owtc_files), total=len(owtc_files)):\n",
    "#     owtc_corpus.extend(split_docs(shard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Load shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "delayed_load = dask.delayed(lambda f: split_docs(np.load(f)))\n",
    "\n",
    "def load_corpus(meta):\n",
    "    files, shapes, dtype = meta\n",
    "    \n",
    "    # Create delayed arrays\n",
    "    delayed_arrays = list(map(delayed_load, files))\n",
    "        \n",
    "    # Concatenate arrays\n",
    "    corpus = da.concatenate([da.from_delayed(array, shape=(shape,), dtype=dtype) \n",
    "                             for array, shape in zip(delayed_arrays, shapes)])\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wt_corpus = load_corpus(wt_meta)\n",
    "wt_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import joblib\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "from dask_ml.metrics.pairwise import pairwise_distances\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    pairwise_distances(wt_corpus, owtc_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_docs = split_docs(np.load(wt_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owtc_docs = split_docs(np.load(owtc_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances, pairwise_distances_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pairwise_distances_chunked(wt_docs, owtc_docs, metric=editdistance.eval, n_jobs=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
