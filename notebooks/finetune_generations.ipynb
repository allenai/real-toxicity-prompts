{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/Desktop/research/language-model-toxicity\n"
     ]
    }
   ],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from scripts.create_db import unpack_scores\n",
    "from scripts.perspective_api_request import request\n",
    "from utils.constants import OUTPUT_DIR, PERSPECTIVE_API_KEY\n",
    "from utils.generation import GPT2Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_dir = OUTPUT_DIR / 'finetune'\n",
    "\n",
    "experiments = [\n",
    "    'finetune_toxicity_percentile_lte2',\n",
    "    'finetune_toxicity_percentile_middle_20_subsample',\n",
    "    'finetune_toxicity_percentile_gte99'\n",
    "]\n",
    "\n",
    "model_dirs = [finetune_dir / e / 'finetune_output' for e in experiments]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_generations(generations: List[str]):\n",
    "    # Score generations\n",
    "    tqdm.write('Fetching responses...')\n",
    "    responses = request(generations, api_key=PERSPECTIVE_API_KEY, requests_per_second=25)\n",
    "    \n",
    "    toxicity_scores = []\n",
    "    for r in responses:\n",
    "        if not r:\n",
    "            toxicity_scores.append(None)\n",
    "            continue\n",
    "        summary_score, span_score = unpack_scores(r)\n",
    "        toxicity_scores.append(summary_score['toxicity'])\n",
    "\n",
    "    return toxicity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: finetune_toxicity_percentile_lte2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd765bd9dab4118bc7506b4d16af1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "num_generations = 10048\n",
    "batch_size = 64\n",
    "max_length = 100\n",
    "\n",
    "for name, model_dir in zip(experiments, model_dirs):\n",
    "    tqdm.write(f'Model: {name}')\n",
    "    generator = GPT2Generator(model_dir)\n",
    "    generations = []\n",
    "    for _ in trange(0, num_generations, batch_size):\n",
    "        out = generator.generate(max_length=max_length,\n",
    "                                 num_return_sequences=batch_size)\n",
    "        generations.extend(out)\n",
    "    \n",
    "    toxicity_scores = score_generations(generations)\n",
    "    \n",
    "    df = pd.DataFrame({\"generation\": generations, \"toxicity\": toxicity_scores})\n",
    "    results[name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
