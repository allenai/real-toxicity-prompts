{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/gws/sgehman/language-model-toxicity\n"
     ]
    }
   ],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import List\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from joblib import Memory, Parallel, delayed, dump, load\n",
    "from lsh import cache, minhash\n",
    "import numpy as np\n",
    "from itertools import chain, islice\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "\n",
    "from utils.constants import DATA_DIR, OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load webtext fingerprints and add to LSHCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups_dir = OUTPUT_DIR / 'lsh_duplicates' / 'char_ngram_5_seeds_100_bands_20_str'\n",
    "\n",
    "fingerprints = np.load(dups_dir / 'fingerprints.npy')\n",
    "with open(dups_dir / 'doc_ids.pkl', 'rb') as f:\n",
    "    doc_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(fingerprints) == len(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "webtext_len = 8_282_020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_fingerprints, wt_doc_ids = fingerprints[:webtext_len], doc_ids[:webtext_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = 100\n",
    "char_ngram = 5\n",
    "hashbytes = 4\n",
    "bands = 10\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = minhash.MinHasher(seeds=seeds, char_ngram=char_ngram, random_state=random_state, hashbytes=hashbytes)\n",
    "if seeds % bands != 0:\n",
    "    raise ValueError('Seeds has to be a multiple of bands. {} % {} != 0'.format(seeds, bands))\n",
    "\n",
    "lshcache = cache.Cache(num_bands=bands, hasher=hasher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d450e843e7495d901bdcb7c75d2d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8282020.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def add_fingerprints(cache, doc_ids, fingerprints):\n",
    "    for doc_id, fingerprint in zip(tqdm(doc_ids), fingerprints):\n",
    "        cache.add_fingerprint(fingerprint, doc_id=doc_id)\n",
    "        \n",
    "add_fingerprints(lshcache, wt_doc_ids, wt_fingerprints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprint Generations and check for near-duplicates in WebText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_generations = load(DATA_DIR / 'gpt2' / 'gpt2_generations.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_feed = zip(map(lambda i: (i, 'gen'), range(len(gpt2_generations))), \n",
    "                    gpt2_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fingerprinter:\n",
    "    def __init__(self, hasher):\n",
    "        self.hasher = hasher\n",
    "\n",
    "    def fingerprint(self, item):\n",
    "        doc_id, doc = item\n",
    "        return doc_id, self.hasher.fingerprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0424dd8969ca4f669a2130485d4b7bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fingerprinting', layout=Layout(flex='2'), max=2500000.0, â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fingerprinter = Fingerprinter(hasher)\n",
    "gen_doc_ids = []\n",
    "gen_fingerprints = []\n",
    "with mp.Pool(processes=96) as pool:\n",
    "    for doc_id, fingerprint in tqdm(pool.imap(fingerprinter.fingerprint, document_feed, chunksize=1_000),\n",
    "                                    desc='Fingerprinting', dynamic_ncols=True, total=len(gpt2_generations)):\n",
    "        gen_doc_ids.append(doc_id)\n",
    "        gen_fingerprints.append(fingerprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fingerprints = np.stack(gen_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(OUTPUT_DIR / 'gpt2_generation_fingerprints.npy', gen_fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(OUTPUT_DIR / 'gpt2_generation_doc_ids.pkl', 'wb') as f:\n",
    "#     pickle.dump(gen_doc_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicates_of(cache, fingerprint):\n",
    "    candidates = set()\n",
    "    for bin_i, bucket in cache.bins_(fingerprint):\n",
    "        bucket_id = hash(tuple(bucket))\n",
    "        candidates.update(cache.bins[bin_i][bucket_id])\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e839e5465e2547e7af8f48c066f9cbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f9f1dde11d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_fingerprints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_duplicates_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlshcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mduplicate_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Duplicates ({len(duplicate_candidates)} found)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-d02964ce6921>\u001b[0m in \u001b[0;36mget_duplicates_of\u001b[0;34m(cache, fingerprint)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbin_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfingerprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbucket_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mcandidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbin_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "duplicate_candidates = set()\n",
    "pbar = tqdm(gen_fingerprints)\n",
    "for f in pbar:\n",
    "    c = get_duplicates_of(lshcache, f)\n",
    "    duplicate_candidates.update(c)\n",
    "    pbar.set_description(f'Duplicates ({len(duplicate_candidates)} found)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
