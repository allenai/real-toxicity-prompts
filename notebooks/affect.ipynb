{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/Desktop/research/language-model-toxicity\n"
     ]
    }
   ],
   "source": [
    "# HACK: use project root as the working directory \n",
    "from pathlib import Path\n",
    "\n",
    "while Path.cwd().name != 'language-model-toxicity':\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from models.affect_lm import AffectGPT2LMHeadModel\n",
    "from utils.constants import OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = OUTPUT_DIR / 'affect' / 'affect_100k_1layer_randomsample_frozen' / 'finetune_output'\n",
    "model = AffectGPT2LMHeadModel.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect2vocab = model.affect.affect2vocab\n",
    "weight = affect2vocab.weight\n",
    "bias = affect2vocab.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = weight.sort(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_vocab = reversed(indices[:,0])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    !\n",
       "1                    \"\n",
       "2                    #\n",
       "3                    $\n",
       "4                    %\n",
       "             ...      \n",
       "50252         Ġregress\n",
       "50253        ĠCollider\n",
       "50254      Ġinformants\n",
       "50255           Ġgazed\n",
       "50256    <|endoftext|>\n",
       "Length: 50257, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "vocab, _ = zip(*vocab.items())\n",
    "vocab = pd.Series(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31030         Ġbastard\n",
       "12131            Ġ2020\n",
       "30248            Ġlame\n",
       "29078           volent\n",
       "10225    Ġcorporations\n",
       "12270            Ġdamn\n",
       "28067            Ġgays\n",
       "6945             ifies\n",
       "22324           Ġidiot\n",
       "18927        something\n",
       "23778              hao\n",
       "6806             arity\n",
       "25164            Ġcrus\n",
       "14372           ĠBaker\n",
       "50112            crazy\n",
       "17974            ieves\n",
       "11456            antom\n",
       "17626      Ġcigarettes\n",
       "19132           Ġpiano\n",
       "9828             Ġwarn\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[top_vocab.tolist()][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from utils.generation import GPT2Generator\n",
    "from utils.constants import OUTPUT_DIR, PERSPECTIVE_API_ATTRIBUTES_LOWER\n",
    "from datasets.affect_dataset import create_affect_vector\n",
    "from models.affect_lm import AffectGPT2LMHeadModel\n",
    "\n",
    "model_dir = OUTPUT_DIR / 'affect' / 'affect_5k_1layer_randomsample_upsample_toxicity_5k' / 'finetune_output'\n",
    "model = AffectGPT2LMHeadModel.from_pretrained(model_dir)\n",
    "model.affect.beta = -1\n",
    "\n",
    "generator = GPT2Generator(model)\n",
    "device = generator.device\n",
    "\n",
    "affects = [create_affect_vector(**{attribute: 1}) for attribute in PERSPECTIVE_API_ATTRIBUTES_LOWER]\n",
    "affects.append(create_affect_vector())\n",
    "affects = torch.tensor(affects).unsqueeze(dim=1).to(device)\n",
    "\n",
    "# prompt = GPT2Generator.STOP_TOKEN\n",
    "prompt = \"Hello there\"\n",
    "out = generator([prompt] * len(affects), max_len=50, affect_labels=affects)\n",
    "\n",
    "for attribute, gen in zip(PERSPECTIVE_API_ATTRIBUTES_LOWER + ('neutral',), out):\n",
    "    print(f'Generation with {attribute}:'.upper(), prompt + gen, sep='\\n', end='\\n\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}