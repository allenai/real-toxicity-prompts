{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdms\n",
    "\n",
    "from constants import DATA_DIR, TEXTS_DIR, PERSPECTIVE_API_RESPONSE_DIR, PERSPECTIVE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\n",
    "    'TOXICITY',\n",
    "    'SEVERE_TOXICITY',\n",
    "    'IDENTITY_ATTACK',\n",
    "    'INSULT',\n",
    "    'THREAT',\n",
    "    'PROFANITY',\n",
    "    'SEXUALLY_EXPLICIT',\n",
    "    'FLIRTATION'\n",
    "]\n",
    "\n",
    "# Generates API client object dynamically based on service name and version.\n",
    "service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=PERSPECTIVE_API_KEY)\n",
    "\n",
    "# All attributes can be found here: \n",
    "# https://github.com/conversationai/perspectiveapi/blob/master/api_reference.md#toxicity-models\n",
    "def request_toxicity(text):\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': text },\n",
    "      'requestedAttributes': {attr: {} for attr in ATTRIBUTES}\n",
    "    }\n",
    "\n",
    "    return service.comments().analyze(body=analyze_request).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_file_for(text_file, chunk_num=None):\n",
    "    if chunk_num == None:\n",
    "        response_filename = text_file.name + '.json'\n",
    "    else:\n",
    "        response_filename = f'{text_file.name}.chunk-{chunk_num}.json'\n",
    "    return PERSPECTIVE_API_RESPONSE_DIR / response_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSPECTIVE_API_FAILURES = DATA_DIR / 'perspective_api_failures.txt'\n",
    "\n",
    "pending_files = set()\n",
    "for text_file in TEXTS_DIR.iterdir():\n",
    "    if not response_file_for(text_file).exists():\n",
    "        pending_files.add(text_file)\n",
    "\n",
    "failure_text_filenames = PERSPECTIVE_API_FAILURES.read_text().split()\n",
    "failure_text_files = set(TEXTS_DIR / filename for filename in failure_text_filenames)\n",
    "\n",
    "# Remove all failed downloads from pending files\n",
    "pending_files -= failure_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import ceil\n",
    "\n",
    "def chunk_text(text: str, chunk_len: int) -> List[str]:\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_len):\n",
    "        chunks.append(text[i:i + chunk_len])\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Test chunking\n",
    "assert len(chunk_text(\"x\" * 2048, 2048)) == 1\n",
    "assert len(chunk_text(\"x\" * 2049, 2048)) == 2\n",
    "assert chunk_text(\"x\" * 2049, 2048)[1] == 'x'\n",
    "assert len(chunk_text(\"x\" * 100, 2048)) == 1\n",
    "assert chunk_text(\"x\" * 100, 2048)[0] == \"x\" * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSPECTIVE_API_SLEEP_SECONDS = 1\n",
    "PERSPECTIVE_API_LEN_LIMIT = 20480\n",
    "\n",
    "for text_file in tqdm(pending_files):\n",
    "    full_text = text_file.read_text()\n",
    "    chunks = chunk_text(full_text, PERSPECTIVE_API_LEN_LIMIT)\n",
    "    \n",
    "    for i, text in enumerate(chunks):\n",
    "        if len(chunks) > 1:\n",
    "            response_file = response_file_for(text_file, chunk_num=i)\n",
    "        else:\n",
    "            response_file = response_file_for(text_file)\n",
    "\n",
    "        try:\n",
    "            response = request_toxicity(text)\n",
    "            with response_file.open('w') as f:\n",
    "                json.dump(response, f)\n",
    "        except:\n",
    "            with PERSPECTIVE_API_FAILURES.open('a') as f:\n",
    "                print(text_file.name, file=f)\n",
    "\n",
    "        # Sleep for 1 second due to rate limiting by API\n",
    "        time.sleep(PERSPECTIVE_API_SLEEP_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
