{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from constants import DATA_DIR, TEXTS_DIR, PERSPECTIVE_API_RESPONSE_DIR, PERSPECTIVE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES = [\n",
    "    'TOXICITY', \n",
    "    'SEVERE_TOXICITY', \n",
    "    'IDENTITY_ATTACK', \n",
    "    'INSULT', \n",
    "    'THREAT', \n",
    "    'PROFANITY', \n",
    "    'SEXUALLY_EXPLICIT', \n",
    "    'FLIRTATION'\n",
    "]\n",
    "\n",
    "# Generates API client object dynamically based on service name and version.\n",
    "service = discovery.build('commentanalyzer', 'v1alpha1', developerKey=PERSPECTIVE_API_KEY)\n",
    "\n",
    "# All attributes can be found here: \n",
    "# https://github.com/conversationai/perspectiveapi/blob/master/api_reference.md#toxicity-models\n",
    "def request_toxicity(text, response_path):\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': text },\n",
    "      'requestedAttributes': {attr: {} for attr in ATTRIBUTES}\n",
    "    }\n",
    "\n",
    "    return service.comments().analyze(body=analyze_request).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_file_for(text_file):\n",
    "    response_filename = text_file.name + '.json'\n",
    "    return PERSPECTIVE_API_RESPONSE_DIR / response_filename\n",
    "\n",
    "\n",
    "unrequested_files = {}\n",
    "for text_file in TEXTS_DIR.iterdir():\n",
    "    response_file = response_file_for(text_file)\n",
    "    if response_file.exists():\n",
    "        continue\n",
    "        \n",
    "    unrequested_files[text_file] = response_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/7853819 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "PERSPECTIVE_API_SLEEP_SECONDS = 1\n",
    "PERSPECTIVE_API_LEN_LIMIT = 20480\n",
    "PERSPECTIVE_API_FAILURES = DATA_DIR / 'perspective_api_failures.txt'\n",
    "\n",
    "for text_file, response_file in tqdm(unrequested_files.items()):\n",
    "    text = text_file.read_text()\n",
    "    if len(text) > PERSPECTIVE_API_LEN_LIMIT:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        response = request_toxicity(text, response_file)\n",
    "        with response_path.open('w') as f:\n",
    "            json.dump(response, f)\n",
    "    except:\n",
    "        with PERSPECTIVE_API_FAILURES.open('a') as f:\n",
    "            print(text_file.name, file=f)\n",
    "\n",
    "    # Sleep for 1 second due to rate limiting by API\n",
    "    time.sleep(PERSPECTIVE_API_SLEEP_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
